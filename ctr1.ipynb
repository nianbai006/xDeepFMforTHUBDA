{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c89e765-a0e9-4f1c-ae8e-8b039def137c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 10:47:28.991781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731984449.442744   48728 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731984449.568030   48728 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-19 10:47:30.621484: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr_torch.models import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81756712-78da-4049-8b41-484fddd2227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train data: 4585it [04:09, 18.40it/s]\n"
     ]
    }
   ],
   "source": [
    "seed = 6\n",
    "torch.manual_seed(seed)  # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed)  # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # 为所有GPU设置随机种子\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]   #C代表类别特征 class\n",
    "dense_features =  ['I' + str(i) for i in range(1, 14)]   #I代表数值特征 int\n",
    "col_names = ['label'] + dense_features + sparse_features\n",
    "test_col_names = dense_features + sparse_features\n",
    "\n",
    "train_data_fraction = 1\n",
    "train_data_chunks = pd.read_csv('./train.txt', names=col_names, sep='\\t', chunksize=10000)\n",
    "train_data = pd.concat(chunk.sample(frac=train_data_fraction, random_state=42) for chunk in tqdm(train_data_chunks, desc=\"Loading train data\"))\n",
    "\n",
    "train_data[sparse_features] = train_data[sparse_features].fillna('-1', )\n",
    "train_data[dense_features] = train_data[dense_features].fillna(0, )\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9277e85e-fe9c-4ec5-b4ab-db70cebcdac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test data: 605it [00:31, 19.05it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data_fraction = 1\n",
    "test_data_chunks = pd.read_csv('./test.txt', names=test_col_names, sep='\\t', chunksize=10000)\n",
    "test_data = pd.concat(chunk.sample(frac=test_data_fraction, random_state=42) for chunk in tqdm(test_data_chunks, desc=\"Loading test data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1b915b-5fad-4868-8385-2ae4308f34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[sparse_features] = test_data[sparse_features].fillna('-1', )   # 类别特征缺失 ，使用-1代替\n",
    "test_data[dense_features] = test_data[dense_features].fillna(0, )        # 数值特征缺失，使用0代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa70890b-fd87-479d-9e67-33d592999876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label Encoding Sparse Features: 100%|██████████| 26/26 [10:24<00:00, 24.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling dense features...\n"
     ]
    }
   ],
   "source": [
    "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "# 使用LabelEncoder()，为类别特征的每一个item编号\n",
    "for feat in tqdm(sparse_features, desc=\"Label Encoding Sparse Features\"):\n",
    "    lbe = LabelEncoder()\n",
    "    all_values = np.concatenate([train_data[feat], test_data[feat]])\n",
    "    lbe.fit(all_values)\n",
    "    train_data[feat] = lbe.transform(train_data[feat])\n",
    "    test_data[feat] = lbe.transform(test_data[feat])\n",
    "    \n",
    "print(\"Scaling dense features...\")\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data[dense_features] = mms.fit_transform(train_data[dense_features])\n",
    "test_data[dense_features] = mms.transform(test_data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c2cc667-9cd2-4c73-be09-8c68fd0441da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 修正词汇大小定义\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=max(train_data[feat].max(), test_data[feat].max()) + 1, embedding_dim=4)\n",
    "                          for feat in sparse_features] + [DenseFeat(feat, 1) for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(\n",
    "    linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 3.generate input data for model\n",
    "\n",
    "train, val = train_test_split(train_data, test_size=0.2, random_state=2020)\n",
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "val_model_input = {name: val[name] for name in feature_names}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5044d8-820a-4248-874b-48453bba01fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n",
      "cuda:0\n",
      "Train on 29337994 samples, validate on 7334499 samples, 7163 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7163it [16:58,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1091s - loss:  0.4635 - binary_crossentropy:  0.4635 - auc:  0.7854 - val_binary_crossentropy:  0.4572 - val_auc:  0.7931\n",
      "\n",
      "test LogLoss 0.4575\n",
      "test AUC 0.7928\n"
     ]
    }
   ],
   "source": [
    " # 4.Define Model,train,predict and evaluate\n",
    "\n",
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    print(\"cpu\")\n",
    "\n",
    "model = xDeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns,\n",
    "               task='binary',\n",
    "               l2_reg_embedding=1e-5, device=device)\n",
    "\n",
    "model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "              metrics=[\"binary_crossentropy\", \"auc\"], )\n",
    "\n",
    "history = model.fit(train_model_input, train[target].values, batch_size=4096, epochs=1, verbose=1,\n",
    "                    validation_split=0.2)\n",
    "pred_ans = model.predict(val_model_input, 256)\n",
    "print(\"\")\n",
    "print(\"test LogLoss\", round(log_loss(val[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(val[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50faa18a-25dc-4468-a636-b63384b83b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions saved to './predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "# 7. 对测试数据进行预测\n",
    "test_model_input = {name: test_data[name] for name in feature_names}\n",
    "test_pred = model.predict(test_model_input, batch_size=256)\n",
    "    \n",
    "# 8. 保存测试数据的预测结果\n",
    "test_data['predicted_label'] = test_pred\n",
    "test_data[['predicted_label']].to_csv('./predictions.csv', index=False)\n",
    "\n",
    "print(\"Test predictions saved to './predictions.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
